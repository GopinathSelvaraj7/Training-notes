{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project Cycle\n",
    "<br>\n",
    "Let's look at how a DataScientist or Machine Learning Engineer would approach a project.\n",
    "<br>\n",
    "<img src=\"MLCycle.JPG\">\n",
    "<br>\n",
    "<center><caption>**Machine Learning Project Cycle**</caption></center>\n",
    "<br>\n",
    "<br>\n",
    "- Understanding the problem statement and deciding the category where this problem would lie, whether supervised( classification, prediction) or unsupervised (clustering).\n",
    "<br>\n",
    "- Looking for the dataset, if we do not get any dataset from the customer. We start with looking for data on open source platforms and scrape data from related websites and modify it based on the task.\n",
    "<br>\n",
    "- Read the data in the programming language specified, which is maximum times it is  python, but sometimes customer needs it on other language.\n",
    "<br>\n",
    "- Prepare the data, if it is in unstructered format convert it into structured format and **[normalize](https://www.geeksforgeeks.org/data-normalization-in-data-mining/)**(scaling the data) the data.\n",
    "<br>\n",
    "- Split the data to train data and evaluation data so that we can check how well the model is performing on blind data (data on which it has not been trained).\n",
    "<br>\n",
    "<img src = \"DataSplit.JPG\">\n",
    "<br>\n",
    "***The percentage of data split depends on how much data we have. If we have a dataset with 10 lakh images then 10% validation data would mean 1 lakh iamges and 2 lakh images for test data, we certainly do not want to miss 3 lakh images for testing.***\n",
    "<br>\n",
    "- Based on the task in hand, whether supervised or unsupervised, we then choose the respective algorithm to be applied on the data. For example: If prediction, we will use *Linear Regression* and if classification we will use *Logistic Regression*\n",
    "<br>\n",
    "- If we are doing linear regression, then we will use Error and R Square to see how well our model is performing and for classification we will see accuracy, precision, recall to check how well our model is performing\n",
    "<br>\n",
    "- After hyphothesis testing, if the model does not perform well try to improve it with different algorithms and feature engineering( transforming raw data to more appropriate features that better represent underlying problem)\n",
    "<br>\n",
    "- Once the model is ready, deploy it using django or flask so that it can be integrated with website or mobile app.\n",
    "<br>\n",
    "<br>\n",
    "<font size=3>***Training time***</font>\n",
    "<img src=\"TrainingCycle.JPG\">\n",
    "<br>\n",
    "<center><caption><font size = 3>**Step by step process for training**</font></caption></center>\n",
    "<br>\n",
    "<br>\n",
    "<font size = 3>***Production time***</font>\n",
    "<img src=\"ProductionCycle.JPG\">\n",
    "<br>\n",
    "<center><caption><font size=3>**Step by step process for production**</font></caption></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Algorithm\n",
    "<br>\n",
    "### Logistic Regression\n",
    "<br>\n",
    "***Logistic Regression*** (also called Logit Regression) is commonly used to estimate the probability that an instance belongs to a particular class (e.g., what is the probability that this email is spam?). If the estimated probability is greater than threshold, then the model predicts that the instance belongs to that class (called the positive class, labeled “1”), and otherwise it predicts that it does not (i.e., it belongs to the negative class, labeled “0”). This makes it a binary classifier.\n",
    "<br>\n",
    "<br>\n",
    "***Binary classification***\n",
    "<img src = \"BinaryClassification.JPG\">\n",
    "<br>\n",
    "<caption><center>**Explaining the selection of class for binary classifier**</center></caption>\n",
    "<br>\n",
    "***Multi-class classification***\n",
    "<img src=\"MultiClassClassification.JPG\">\n",
    "<br>\n",
    "<caption><center>**Explaining the selection of class for multi-class classifier**</center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets work with data now\n",
    "#start by importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the data file\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above data which we have is ffrom the National Institute of Diabetes and Digestive and Kidney Diseases (https://www.kaggle.com/uciml/pima-indians-diabetes-database). In this data we have diabetes outcome based on diferent parameters where 1 would denote ***Diabetic*** and 0 would denote ***Not Diabetic***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   0.000\n",
       "Glucose                     151.000\n",
       "BloodPressure                90.000\n",
       "SkinThickness                46.000\n",
       "Insulin                       0.000\n",
       "BMI                          42.100\n",
       "DiabetesPedigreeFunction      0.371\n",
       "Age                          21.000\n",
       "Outcome                       1.000\n",
       "Name: 580, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[580]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Lets seperate the dependent and independent variable before training\"\"\"\n",
    "label = data['Outcome']\n",
    "data.drop(\"Outcome\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (192, 8) (576,) (192,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Split the data into train and test\"\"\"\n",
    "train_data, test_data, train_label, test_label = train_test_split(data,label, test_size=0.25)\n",
    "print(train_data.shape, test_data.shape, train_label.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    133\n",
       "1     59\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akshi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "model = lr.fit(train_data, train_label)\n",
    "train_pred = model.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       367\n",
      "           1       0.74      0.62      0.67       209\n",
      "\n",
      "    accuracy                           0.78       576\n",
      "   macro avg       0.77      0.75      0.76       576\n",
      "weighted avg       0.78      0.78      0.78       576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_label,train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[322  45]\n",
      " [ 80 129]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(train_label, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>90</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>42.1</td>\n",
       "      <td>0.371</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "580            0      151             90             46        0  42.1   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "580                     0.371   21  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   0.000\n",
       "Glucose                     151.000\n",
       "BloodPressure                90.000\n",
       "SkinThickness                46.000\n",
       "Insulin                       0.000\n",
       "BMI                          42.100\n",
       "DiabetesPedigreeFunction      0.371\n",
       "Age                          21.000\n",
       "Name: 580, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[580]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       133\n",
      "           1       0.64      0.51      0.57        59\n",
      "\n",
      "    accuracy                           0.76       192\n",
      "   macro avg       0.72      0.69      0.70       192\n",
      "weighted avg       0.75      0.76      0.75       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_data)\n",
    "print(classification_report(test_label, test_pred))\n",
    "print(confusion_matrix(test_label, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematics behind (Logistic Regression)\n",
    "<br>\n",
    "***Logistic regression*** is part of regression family as it uses the line equation in the backend.\n",
    "<br>\n",
    "<br>\n",
    "<center><font size=5>$\\hat{y}= w_1x_1+w_2x_2+w_3x_3+w_4x_4+w_5x_5+w_6x_6+w_7x_7+w_8x_8 +b$</font></center>\n",
    "<br>\n",
    "<br>\n",
    "Now lets us see how it is different from *Linear Regression*\n",
    "<br>\n",
    "<br>\n",
    "<center><font size=5>$\\sigma(\\hat{y}) = \\frac{1}{1+e^{-\\hat{y}}}$</font></center>\n",
    "<br>\n",
    "$\\sigma(\\hat{y})$: sigmoid is sometimes also known as the logistic function. It is a non linear function used not only in machine learning but also for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg(x):\n",
    "    \"\"\"This function will implement Linear Equation which is y_hat = wx+b\n",
    "    parameters\n",
    "    x: independent variables in the form of array\n",
    "    \n",
    "    output\n",
    "    y_hat: computed for n features\"\"\"\n",
    "    m,n = x.shape\n",
    "    w = np.random.randn(1, n)\n",
    "    b = np.random.randn(1,1)\n",
    "    line_eq = []\n",
    "    for i in range(x.shape[1]):\n",
    "        w_i = w[:,i].reshape(1,1)\n",
    "        x_i = x[:,i].reshape(m,1)\n",
    "        line_eq.append(np.dot(w,x.T)+b)\n",
    "    return np.sum(line_eq,axis=0)\n",
    "\n",
    "def sigmoid(y_hat):\n",
    "    \"\"\"This function will implement sigmoid function\n",
    "    parameters\n",
    "    y_hat: y_hat calculated after linear equation\n",
    "    \n",
    "    outpur\n",
    "    sigmoid: it will give us sigmoid of y_hat\n",
    "    \"\"\"\n",
    "    sigmoid = 1/(1+np.exp(-y_hat))\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred= linear_reg(np.array(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 3.73850278e-25, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.42561201e-139, 4.25315951e-080, 3.47380844e-103,\n",
       "        0.00000000e+000, 0.00000000e+000, 4.87684003e-069,\n",
       "        0.00000000e+000, 1.35880516e-116, 0.00000000e+000,\n",
       "        6.51538975e-072, 5.48507949e-067, 3.51040889e-112,\n",
       "        2.25657096e-112, 0.00000000e+000, 0.00000000e+000,\n",
       "        4.82603620e-103, 0.00000000e+000, 9.64368917e-075,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        3.04975065e-092, 3.97049086e-116, 1.88105001e-110,\n",
       "        0.00000000e+000, 0.00000000e+000, 2.58330060e-106,\n",
       "        0.00000000e+000, 0.00000000e+000, 2.89021517e-076,\n",
       "        3.00011716e-125, 0.00000000e+000, 9.38194897e-222,\n",
       "        1.14228036e-049, 1.69293127e-124, 0.00000000e+000,\n",
       "        1.65246554e-100, 1.17915673e-126, 1.04179565e-100,\n",
       "        0.00000000e+000, 0.00000000e+000, 1.12094232e-093,\n",
       "        2.01737160e-093, 0.00000000e+000, 5.57193199e-103,\n",
       "        1.22364907e-126, 1.49372233e-079, 2.79511889e-067,\n",
       "        5.71687643e-113, 1.14010644e-073, 1.69545868e-291,\n",
       "        1.12764808e-178, 3.33411559e-148, 0.00000000e+000,\n",
       "        0.00000000e+000, 3.01288424e-053, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.90826484e-089, 0.00000000e+000,\n",
       "        5.25322197e-052, 1.12205201e-096, 3.30982107e-054,\n",
       "        0.00000000e+000, 7.83888423e-093, 4.55360164e-092,\n",
       "        2.45841136e-089, 5.68506878e-088, 1.03182648e-169,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        5.18357800e-110, 0.00000000e+000, 1.68214632e-071,\n",
       "        3.05835186e-040, 3.28796851e-069, 2.54931798e-099,\n",
       "        3.46622026e-102, 9.18837689e-078, 3.79652782e-077,\n",
       "        2.05129973e-049, 2.25022546e-301, 5.99032909e-073,\n",
       "        1.78926223e-087, 0.00000000e+000, 3.34908467e-156,\n",
       "        1.30988790e-296, 0.00000000e+000, 2.43243691e-071,\n",
       "        1.48289045e-041, 0.00000000e+000, 8.06528548e-265,\n",
       "        1.85457446e-099, 2.94191548e-263, 0.00000000e+000,\n",
       "        4.48546168e-083, 1.16071795e-282, 3.16059541e-284,\n",
       "        0.00000000e+000, 3.02395533e-090, 2.39171636e-070,\n",
       "        4.76888200e-041, 1.55590429e-177, 1.47072490e-063,\n",
       "        0.00000000e+000, 1.83770049e-028, 0.00000000e+000,\n",
       "        1.29374848e-142, 6.18807876e-178, 0.00000000e+000,\n",
       "        0.00000000e+000, 5.12745884e-187, 6.31222375e-060,\n",
       "        0.00000000e+000, 1.73223689e-102, 1.06571636e-085,\n",
       "        2.25202928e-068, 2.27727420e-081, 2.48785411e-213,\n",
       "        0.00000000e+000, 3.24843878e-110, 0.00000000e+000,\n",
       "        1.89574541e-108, 2.95665465e-055, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.42847565e-080, 0.00000000e+000, 9.01545548e-097,\n",
       "        0.00000000e+000, 2.22960475e-111, 4.05218906e-206,\n",
       "        0.00000000e+000, 8.46831959e-220, 0.00000000e+000,\n",
       "        4.49084384e-063, 0.00000000e+000, 5.42166599e-086,\n",
       "        8.72777808e-108, 9.88544367e-275, 1.65993513e-097,\n",
       "        0.00000000e+000, 1.60319134e-044, 7.95128041e-105,\n",
       "        0.00000000e+000, 3.06402225e-116, 4.71599560e-064,\n",
       "        0.00000000e+000, 4.50417148e-073, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.26212359e-128, 5.00598505e-145,\n",
       "        0.00000000e+000, 0.00000000e+000, 1.21142530e-220,\n",
       "        0.00000000e+000, 2.48120112e-115, 0.00000000e+000,\n",
       "        0.00000000e+000, 2.27639055e-076, 1.24205958e-063,\n",
       "        0.00000000e+000, 2.81283878e-099, 2.04990754e-077,\n",
       "        5.47456022e-072, 1.34354402e-297, 5.83886517e-073,\n",
       "        0.00000000e+000, 1.81570488e-100, 2.22581014e-239,\n",
       "        4.06703097e-241, 0.00000000e+000, 1.52154344e-074,\n",
       "        0.00000000e+000, 1.71015714e-107, 5.80390023e-088,\n",
       "        6.28786363e-059, 0.00000000e+000, 5.46478259e-099,\n",
       "        4.17408632e-058, 6.24276118e-086, 1.91130755e-146,\n",
       "        0.00000000e+000, 9.96252721e-270, 0.00000000e+000,\n",
       "        0.00000000e+000, 7.74874850e-057, 0.00000000e+000,\n",
       "        5.75093913e-101, 2.13516004e-149, 6.05254123e-101,\n",
       "        0.00000000e+000, 4.91674797e-053, 2.10471706e-210,\n",
       "        0.00000000e+000, 0.00000000e+000, 1.15658670e-064,\n",
       "        1.05674649e-073, 2.46021442e-078, 1.38257522e-194,\n",
       "        0.00000000e+000, 2.24863842e-089, 0.00000000e+000,\n",
       "        2.04615421e-102, 0.00000000e+000, 1.01724947e-140,\n",
       "        1.48352475e-072, 1.63308932e-120, 5.81382409e-149,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 4.20384428e-083,\n",
       "        1.65851828e-090, 0.00000000e+000, 1.21305045e-107,\n",
       "        3.39326941e-110, 0.00000000e+000, 2.74281477e-230,\n",
       "        2.70706126e-166, 9.81115912e-056, 4.87538625e-127,\n",
       "        0.00000000e+000, 6.16231284e-249, 2.55708257e-078,\n",
       "        0.00000000e+000, 1.64710224e-168, 9.69624464e-078,\n",
       "        1.12048115e-206, 4.42259482e-097, 0.00000000e+000,\n",
       "        2.22413167e-105, 5.21646451e-116, 4.32203357e-044,\n",
       "        2.21892943e-071, 0.00000000e+000, 5.43452546e-073,\n",
       "        0.00000000e+000, 0.00000000e+000, 5.72170826e-132,\n",
       "        1.18942124e-099, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.68531902e-067, 4.03987524e-099, 1.08795418e-061,\n",
       "        1.74501238e-218, 8.13374601e-082, 0.00000000e+000,\n",
       "        1.87719070e-092, 1.21892835e-108, 2.02264669e-081,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        2.83960859e-103, 8.66383469e-090, 1.02981640e-119,\n",
       "        1.79523980e-083, 1.35483362e-293, 1.94530261e-098,\n",
       "        3.06338455e-114, 1.22437675e-052, 2.17544108e-101,\n",
       "        1.17171310e-127, 7.44937963e-249, 7.78542906e-072,\n",
       "        7.96339746e-218, 9.22156741e-113, 7.60482351e-280,\n",
       "        2.36932914e-097, 0.00000000e+000, 1.83820070e-092,\n",
       "        0.00000000e+000, 3.72294599e-077, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.31855421e-103, 6.08081275e-078,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        7.55160698e-219, 0.00000000e+000, 3.24314986e-183,\n",
       "        9.40803770e-308, 0.00000000e+000, 0.00000000e+000,\n",
       "        4.36234206e-111, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 1.59390034e-099,\n",
       "        1.02534949e-109, 0.00000000e+000, 2.01747547e-225,\n",
       "        5.52587895e-079, 6.51822386e-078, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 9.21005841e-100, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 3.57824237e-117,\n",
       "        0.00000000e+000, 4.66155029e-249, 5.27625275e-090,\n",
       "        0.00000000e+000, 3.72846780e-121, 0.00000000e+000,\n",
       "        3.00875521e-090, 1.48785323e-086, 1.13818476e-221,\n",
       "        6.51818799e-089, 0.00000000e+000, 0.00000000e+000,\n",
       "        7.51163916e-118, 0.00000000e+000, 3.15724414e-308,\n",
       "        1.17162242e-107, 1.20664501e-226, 5.03668890e-135,\n",
       "        9.50923700e-091, 5.19968073e-236, 0.00000000e+000,\n",
       "        1.76269890e-106, 4.42800518e-085, 0.00000000e+000,\n",
       "        2.23955697e-112, 0.00000000e+000, 1.25193702e-291,\n",
       "        1.07909264e-051, 2.72961130e-076, 3.97681136e-103,\n",
       "        0.00000000e+000, 0.00000000e+000, 1.00033241e-085,\n",
       "        3.78591239e-291, 2.48953423e-074, 2.46046738e-068,\n",
       "        2.24625805e-074, 4.76263961e-089, 1.43331123e-188,\n",
       "        2.39084367e-059, 9.69992673e-111, 0.00000000e+000,\n",
       "        6.85945949e-173, 1.28230289e-294, 0.00000000e+000,\n",
       "        0.00000000e+000, 2.77241893e-118, 5.45721934e-127,\n",
       "        2.86932899e-119, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.16608196e-075, 1.13721669e-059, 3.88944414e-250,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        5.02718482e-264, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.18509052e-300, 0.00000000e+000,\n",
       "        7.93003368e-100, 1.21397726e-304, 0.00000000e+000,\n",
       "        4.51524117e-064, 0.00000000e+000, 1.88671419e-240,\n",
       "        0.00000000e+000, 3.80370446e-219, 3.41754488e-105,\n",
       "        4.33639908e-122, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.19650465e-098, 0.00000000e+000,\n",
       "        0.00000000e+000, 2.11069413e-086, 0.00000000e+000,\n",
       "        0.00000000e+000, 2.44967872e-101, 3.10683000e-046,\n",
       "        3.76458371e-123, 1.99962176e-069, 2.70380045e-105,\n",
       "        0.00000000e+000, 2.47107406e-096, 1.39313020e-106,\n",
       "        0.00000000e+000, 2.53081092e-084, 1.68107618e-049,\n",
       "        1.34558815e-112, 0.00000000e+000, 9.38506774e-102,\n",
       "        0.00000000e+000, 0.00000000e+000, 3.02970531e-260,\n",
       "        0.00000000e+000, 0.00000000e+000, 9.02396105e-069,\n",
       "        1.14859409e-118, 2.85818085e-042, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.45258588e-288, 0.00000000e+000,\n",
       "        1.67791402e-081, 0.00000000e+000, 0.00000000e+000,\n",
       "        2.37878676e-054, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.72153708e-076, 0.00000000e+000,\n",
       "        8.66115735e-230, 1.44332126e-068, 3.25748015e-065,\n",
       "        1.11175719e-107, 1.93794643e-138, 6.02238533e-081,\n",
       "        3.32514149e-054, 1.06747922e-072, 6.52209647e-110,\n",
       "        1.57266745e-219, 0.00000000e+000, 8.70525191e-082,\n",
       "        6.20549389e-086, 1.32471895e-198, 1.78113566e-269,\n",
       "        0.00000000e+000, 1.08539339e-277, 3.16770210e-260,\n",
       "        0.00000000e+000, 3.85131118e-066, 0.00000000e+000,\n",
       "        5.80693469e-126, 0.00000000e+000, 7.88959825e-156,\n",
       "        3.69597369e-104, 3.51733432e-293, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.29808656e-277, 2.05295422e-042,\n",
       "        2.80320401e-259, 7.44673299e-093, 1.54408545e-073,\n",
       "        0.00000000e+000, 6.69782696e-161, 0.00000000e+000,\n",
       "        1.37343653e-117, 0.00000000e+000, 6.49065390e-113,\n",
       "        4.02521893e-099, 4.38993783e-089, 8.80552369e-096,\n",
       "        3.97733812e-067, 1.56978977e-112, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 2.88444311e-127,\n",
       "        0.00000000e+000, 3.30308688e-094, 3.86060570e-226,\n",
       "        0.00000000e+000, 1.95081051e-112, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 3.32207855e-075,\n",
       "        1.63309517e-134, 6.20666352e-277, 1.31922529e-090,\n",
       "        6.35434749e-106, 0.00000000e+000, 7.61443205e-054,\n",
       "        5.28542327e-122, 1.03375465e-069, 1.10854419e-286,\n",
       "        0.00000000e+000, 0.00000000e+000, 3.27809776e-273,\n",
       "        2.00359575e-090, 9.82207304e-092, 0.00000000e+000,\n",
       "        2.02644291e-109, 6.48274139e-077, 0.00000000e+000,\n",
       "        0.00000000e+000, 2.02378451e-300, 2.74747569e-106,\n",
       "        4.83021156e-121, 0.00000000e+000, 1.61898169e-096,\n",
       "        2.16689396e-052, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.22403537e-100, 2.44513077e-095,\n",
       "        0.00000000e+000, 8.14054458e-265, 0.00000000e+000,\n",
       "        3.50081757e-076, 2.17013038e-105, 4.39515275e-073,\n",
       "        4.19874689e-065, 4.34265020e-301, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.98645994e-059, 0.00000000e+000,\n",
       "        9.42007929e-064, 4.00870083e-302, 1.50637665e-096,\n",
       "        5.66242881e-246, 4.74387161e-101, 7.63369984e-065,\n",
       "        2.91628797e-073, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 1.65409938e-127,\n",
       "        4.78111932e-241, 4.76489761e-302, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        3.42152558e-114, 9.33379199e-080, 0.00000000e+000,\n",
       "        1.54385733e-099, 7.99207560e-203, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.04535982e-100, 2.25747186e-100,\n",
       "        2.61699011e-144, 1.25571035e-080, 6.55108026e-102,\n",
       "        0.00000000e+000, 0.00000000e+000, 8.42212271e-250,\n",
       "        3.82463231e-049, 0.00000000e+000, 9.50053025e-137,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.50270951e-066, 1.53473238e-047, 4.32691804e-222,\n",
       "        0.00000000e+000, 0.00000000e+000, 2.32752028e-303,\n",
       "        0.00000000e+000, 5.17425237e-066, 1.47479255e-095,\n",
       "        5.23548276e-217, 2.08500187e-109, 1.04851406e-095,\n",
       "        1.11250757e-130, 4.65931279e-091, 0.00000000e+000,\n",
       "        3.41565146e-059, 7.68978138e-106, 3.47579962e-068,\n",
       "        0.00000000e+000, 6.74011621e-064, 3.66714096e-144,\n",
       "        0.00000000e+000, 3.50749768e-087, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 8.18656143e-070,\n",
       "        1.61368238e-154, 2.75277649e-095, 0.00000000e+000,\n",
       "        2.71542353e-064, 1.32605658e-090, 1.43917141e-096,\n",
       "        0.00000000e+000, 9.85964758e-127, 7.65074259e-097,\n",
       "        0.00000000e+000, 7.04803557e-190, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.48542801e-092, 0.00000000e+000,\n",
       "        3.79376949e-059, 1.97615228e-065, 2.15290831e-095,\n",
       "        4.35846561e-116, 1.17872093e-087, 0.00000000e+000,\n",
       "        1.36594696e-068, 1.71133802e-112, 0.00000000e+000,\n",
       "        3.60725469e-059, 6.10792369e-262, 6.75582444e-054,\n",
       "        1.72326273e-058, 1.74986312e-091, 1.13524631e-073,\n",
       "        2.96336819e-082, 0.00000000e+000, 5.10914134e-060,\n",
       "        0.00000000e+000, 1.89999800e-078, 2.77821612e-096,\n",
       "        9.20497375e-084, 2.69363216e-262, 0.00000000e+000,\n",
       "        2.01473752e-193, 0.00000000e+000, 6.95483157e-074,\n",
       "        7.49782805e-101, 4.04215165e-090, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.38352446e-076, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 1.25190363e-069,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 7.66544322e-104, 7.74924367e-287,\n",
       "        5.31343612e-116, 5.80931305e-133, 0.00000000e+000,\n",
       "        0.00000000e+000, 2.78607973e-127, 0.00000000e+000,\n",
       "        1.93487294e-131, 1.47632303e-115, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 5.43496358e-061,\n",
       "        1.49684410e-239, 0.00000000e+000, 7.71474269e-107,\n",
       "        3.20259912e-105, 1.30175983e-107, 3.80605136e-058,\n",
       "        1.76077868e-078, 0.00000000e+000, 1.13676545e-197,\n",
       "        3.37965089e-120, 0.00000000e+000, 4.26688444e-070,\n",
       "        6.09241435e-088, 0.00000000e+000, 6.39674872e-064,\n",
       "        1.85969149e-084, 0.00000000e+000, 0.00000000e+000,\n",
       "        1.14334844e-073, 2.77450215e-112, 0.00000000e+000,\n",
       "        0.00000000e+000, 1.94441938e-052, 0.00000000e+000,\n",
       "        0.00000000e+000, 3.72155025e-073, 0.00000000e+000,\n",
       "        1.48529853e-080, 0.00000000e+000, 8.85930201e-120,\n",
       "        1.03974226e-125, 4.39037428e-116, 0.00000000e+000,\n",
       "        1.47972718e-098, 1.43769641e-089, 0.00000000e+000,\n",
       "        1.36076695e-112, 0.00000000e+000, 0.00000000e+000,\n",
       "        3.64943531e-172, 3.58611147e-142, 0.00000000e+000,\n",
       "        2.03793769e-064, 0.00000000e+000, 0.00000000e+000,\n",
       "        5.46877035e-112, 0.00000000e+000, 5.19594021e-114,\n",
       "        2.43991457e-074, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000, 2.59211972e-069, 5.23428495e-118,\n",
       "        0.00000000e+000, 1.45531619e-083, 2.56698265e-067,\n",
       "        8.53375416e-059, 0.00000000e+000, 1.13327488e-067,\n",
       "        0.00000000e+000, 0.00000000e+000, 5.62162488e-077,\n",
       "        6.82422313e-100, 0.00000000e+000, 3.23409013e-096,\n",
       "        0.00000000e+000, 9.02742645e-077, 0.00000000e+000,\n",
       "        0.00000000e+000, 0.00000000e+000, 4.00575307e-098,\n",
       "        0.00000000e+000, 0.00000000e+000, 1.99654557e-115,\n",
       "        1.48281316e-270, 0.00000000e+000, 5.00888806e-109,\n",
       "        1.17627752e-072, 0.00000000e+000, 8.38204366e-084,\n",
       "        0.00000000e+000, 1.84940163e-135, 0.00000000e+000,\n",
       "        7.42540607e-125, 6.12951581e-089, 3.18130960e-061,\n",
       "        3.96889879e-130, 2.39175374e-124, 2.38906095e-151,\n",
       "        3.51002714e-074, 0.00000000e+000, 3.39300241e-096,\n",
       "        0.00000000e+000, 1.14476085e-087, 8.40326849e-079]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = linear_reg(np.array(data))\n",
    "sigmoid(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy loss\n",
    "<br>\n",
    "Insted of ***Mean Squared Error*** we will use ***Cross-entropy Loss*** which is also known as log loss.\n",
    "<br>\n",
    "<br>\n",
    "<center><font size=5>$J(y,\\hat{y})=-\\frac{1}{m}\\sum_{i=1}^m[y_ilog(\\hat{y_i})+(1-y_i)log(1-\\hat{y_i})]$</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(y_hat):\n",
    "    \"\"\"We will calculate the cost function for logistic regression\n",
    "    parameters\n",
    "    y_hat: input feature after applying sigmoid on linear equation\n",
    "    output\n",
    "    cost: computed cost value for data\n",
    "    \"\"\"\n",
    "    cost =  -(np.mean(Y * np.log(s_y_hat) + (1-Y) * np.log(1-s_y_hat)))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising Loss\n",
    "\n",
    "Let us look what we get when we take derivative of sigmoid and cost function\n",
    "<br>\n",
    "***Derivative of sigmoid:***\n",
    "<center><font size = 5>$\\sigma^{'}(\\hat{y}) = \\sigma(\\hat{y})(1-\\sigma(\\hat{y}))$</font></center>\n",
    "<br>\n",
    "***Derivative of cost function:***\n",
    "**For parameter w**\n",
    "<br>\n",
    "<center><font size = 5>$\\frac{d}{dw}J(w,b) = \\frac{1}{m}\\sum_{i=1}^m(x(\\sigma(\\hat{y}) - y))$</font></center>\n",
    "<br>\n",
    "**For parameter b**\n",
    "<br>\n",
    "<center><font size = 5>$\\frac{d}{db}J(w,b) = \\frac{1}{m}\\sum_{i=1}^m(\\sigma(\\hat{y}) - y)$</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimisation(x,y_hat,y,w,b):\n",
    "    \"\"\"This function will calculate the derivative of sigmoid and cost with respect to w and b\n",
    "    parameters\n",
    "    x: independent variables in the form of array\n",
    "    y_hat: sigmoid of linear equation\n",
    "    y: dependent variable in the form of array\n",
    "    w, b: weights and bias\n",
    "    \n",
    "    output \n",
    "    ds: derivative of sigmoid\n",
    "    dw: derivative of cost with respect to w\n",
    "    db: derivative of cost with respect to b\"\"\"\n",
    "    ds = y_hat(1-y_hat)\n",
    "    dw = np.mean((np.dot(x.T,(y_hat - y))))\n",
    "    db = (np.mean(y_hat-y))\n",
    "    return ds, dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing\n",
    "<br>\n",
    "We will first create a confusion matrix\n",
    "<img src=\"confusionMatrix.JPG\">\n",
    "\n",
    "**Precision:** <font size=3>$\\frac{TP}{TP+FP}$</font>\n",
    "<br>\n",
    "<br>\n",
    "**Recall:** <font size=3>$\\frac{TP}{TP+FN}$</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
